#business logic aÅŸamasÄ± / Ã§oklu dil destekli 
from typing import List, Dict
from src.model.sentiment_model import SentimentModel
from src.schemas import SentimentResponse

class SentimentService:
    def __init__(self):
        self.model = SentimentModel()
        
        # ğŸŒ BILINGUAL KEYWORDS (TR + EN)
        # Hem TÃ¼rkÃ§e hem Ä°ngilizce negatif kelimeleri buraya ekliyoruz.
        # Bu kelimeler geÃ§iyorsa modele sormaya gerek yok, direkt NEGATÄ°F basacaÄŸÄ±z.
        self.negative_keywords = {
            # Turkish
            "kÃ¶tÃ¼", "berbat", "Ã§Ã¶p", "beÄŸenmedim", "piÅŸman", 
            "problem", "bozuk", "hata", "iÄŸrenÃ§", "vasat",
            "dandik", "rezalet", "felaket", "saÃ§ma", "zaman kaybÄ±",
            # English
            "bad", "terrible", "awful", "trash", "worst", 
            "boring", "waste", "disaster", "poor", "hate",
            "sucks", "horrible", "garbage", "crap", "stupid"
        }
        
        # Basit bir bellek-iÃ§i istatistik tutucu
        self.stats = {
            "Total": 0,
            "Pozitif": 0,
            "Negatif": 0,
            "NÃ¶tr": 0
        }

    def analyze_text(self, text: str) -> SentimentResponse:
        """
        Tekli metin analizi (Eski endpointler iÃ§in uyumluluk).
        """
        # Batch mantÄ±ÄŸÄ±nÄ± Ã§aÄŸÄ±rÄ±p ilk sonucu alÄ±yoruz, kod tekrarÄ± yok.
        result = self.analyze_batch([text])["results"][0]
        
        # Response modeline Ã§evir (Pydantic)
        return SentimentResponse(
            sentiment=result["sentiment"],
            confidence=result["confidence"]
        )

    def analyze_batch(self, texts: List[str]) -> Dict[str, List[Dict]]:
        """
        Hibrit Batch Analizi:
        1. Kural TabanlÄ± Ã–n Eleme (HÄ±z KazandÄ±rÄ±r)
        2. Sadece gerekenleri Yapay Zekaya sorma
        3. SonuÃ§larÄ± birleÅŸtirme
        """
        final_results = [None] * len(texts) # SonuÃ§lar iÃ§in yer tut
        indices_for_ai = [] # AI'ya gideceklerin orijinal sÄ±ra numarasÄ±
        texts_for_ai = []   # AI'ya gidecek metinler

        # --- FAZ 1: Kural TabanlÄ± Tarama ---
        for i, text in enumerate(texts):
            original = (text or "").strip()
            clean = original.lower() # Sadece kural kontrolÃ¼ iÃ§in kÃ¼Ã§Ã¼lt

            found_keyword = False
            
            # YasaklÄ± kelime kontrolÃ¼
            for word in clean.split():
                if word in self.negative_keywords:
                    # YakaladÄ±k! Modele gitmeye gerek yok.
                    final_results[i] = {
                        "sentiment": "Negatif",
                        "confidence": 1.0
                    }
                    found_keyword = True
                    
                    # Ä°statistik gÃ¼ncelle
                    self.stats["Negatif"] += 1
                    self.stats["Total"] += 1
                    break

            # EÄŸer kurala takÄ±lmadÄ±ysa AI listesine ekle
            if not found_keyword:
                indices_for_ai.append(i)
                texts_for_ai.append(original) # Modele ORÄ°JÄ°NAL metni gÃ¶nder (Cased model hassasiyeti iÃ§in)

        # --- FAZ 2: Yapay Zeka (Sadece gerekenler iÃ§in) ---
        if texts_for_ai:
            ai_results = self.model.predict_batch(texts_for_ai)

            # SonuÃ§larÄ± doÄŸru yerlerine (indekslerine) yerleÅŸtir
            for original_index, result in zip(indices_for_ai, ai_results):
                final_results[original_index] = result
                
                # Ä°statistik gÃ¼ncelle
                sentiment = result.get("sentiment")
                if sentiment in self.stats:
                    self.stats[sentiment] += 1
                self.stats["Total"] += 1

        return {"results": final_results}

    def get_statistics(self):
        return self.stats